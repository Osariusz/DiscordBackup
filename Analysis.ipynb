{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastapi import FastAPI, responses\n",
    "import pandas as pd\n",
    "import uvicorn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get the path to the main folder (CWD for the notebook)\n",
    "main_folder = os.getcwd()\n",
    "\n",
    "# Construct the path to the src directory\n",
    "src_path = os.path.join(main_folder, \"src\")\n",
    "\n",
    "# Add the src directory to the module search path if it's not already there\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Verify the path is added\n",
    "print(\"Updated sys.path:\", sys.path)\n",
    "\n",
    "from VariableTypeEnum import VariableTypeEnum\n",
    "from VarsManager import VarsManager\n",
    "from src.ChannelAnalysis import ChannelAnalysis\n",
    "from LoreInfo import regions, bot_users, lore_channels, human_countries, ml_channels, dig_channels, other_lore_words, special_characters, emojis, lore_nicknames, server_names\n",
    "from src.Plotting import Plotting\n",
    "from typing import Callable\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "vars_manager = VarsManager()\n",
    "channel_names = vars_manager.vars[VariableTypeEnum.CHANNEL_NAMES]\n",
    "user_names = vars_manager.vars[VariableTypeEnum.USER_NICKNAMES]\n",
    "def get_channel_name(id):\n",
    "    id = str(id)\n",
    "    if(id in channel_names):\n",
    "        return channel_names[id]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_channel_analysis: ChannelAnalysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Preparing data\")\n",
    "    main_channel_analysis = ChannelAnalysis(content_matters=True)\n",
    "    logging.info(\"Starting the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_analysis: ChannelAnalysis = ChannelAnalysis(message_df=main_channel_analysis.messages_df)\n",
    "channel_analysis.restrict_to_channels(lore_channels)\n",
    "\n",
    "logging.getLogger().info(f\"Plotting message count by day\")\n",
    "df: pd.DataFrame = channel_analysis.day_number_of_messages().copy()\n",
    "creation_date_series_lore = df[\"created_at\"].value_counts()\n",
    "creation_date_series_lore = creation_date_series_lore.sort_index()\n",
    "\n",
    "lore_channels_fig = px.histogram(creation_date_series_lore, \n",
    "                    x = creation_date_series_lore.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red'],\n",
    "                    nbins=len(creation_date_series_lore))\n",
    "lore_channels_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels: list[int] = None\n",
    "channel_analysis: ChannelAnalysis = ChannelAnalysis(message_df=main_channel_analysis.messages_df)\n",
    "channel_analysis.restrict_to_channels(all_channels)\n",
    "\n",
    "logging.getLogger().info(f\"Plotting message count by day\")\n",
    "df: pd.DataFrame = channel_analysis.day_number_of_messages().copy()\n",
    "creation_date_series_all = df[\"created_at\"].value_counts()\n",
    "creation_date_series_all = creation_date_series_all.sort_index()\n",
    "\n",
    "all_channels_fig = px.histogram(creation_date_series_all, \n",
    "                    x = creation_date_series_all.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    nbins=len(creation_date_series_all))\n",
    "all_channels_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both figure\n",
    "# Combine the histograms\n",
    "fig = go.Figure()\n",
    "\n",
    "creation_date_series_all_normalized = creation_date_series_all.copy()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore.copy()\n",
    "creation_date_series_all_normalized  = creation_date_series_all_normalized / creation_date_series_all_normalized.max()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_normalized / creation_date_series_lore_normalized.max()\n",
    "\n",
    "all_channels_fig_probability = px.bar(creation_date_series_all_normalized, \n",
    "                    x = creation_date_series_all_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "lore_channels_fig_probability = px.bar(creation_date_series_lore_normalized, \n",
    "                    x = creation_date_series_lore_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "# Add traces from both histograms\n",
    "for trace in all_channels_fig_probability.data:\n",
    "    trace.opacity = 1\n",
    "    fig.add_trace(trace)\n",
    "for trace in lore_channels_fig_probability.data:\n",
    "    trace.opacity = 0.5\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_traces(marker_line_width=0)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Lore channels on top of all channels\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Messages to max ratio\",\n",
    "    barmode='overlay',\n",
    "    template=\"plotly\",\n",
    "    bargap=0,\n",
    "    bargroupgap=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels: list[int] = None\n",
    "channel_analysis: ChannelAnalysis = ChannelAnalysis(message_df=main_channel_analysis.messages_df)\n",
    "channel_analysis.restrict_to_channels(all_channels)\n",
    "\n",
    "logging.getLogger().info(f\"Plotting message count by day\")\n",
    "df: pd.DataFrame = channel_analysis.day_number_of_messages().copy()\n",
    "creation_date_series_all_yearly = df[\"created_at\"].value_counts()\n",
    "creation_date_series_all_yearly = creation_date_series_all_yearly.sort_index()\n",
    "\n",
    "creation_date_series_all_yearly.index = pd.to_datetime(creation_date_series_all_yearly.index).year\n",
    "\n",
    "all_channels_fig = px.histogram(creation_date_series_all_yearly, \n",
    "                    x = creation_date_series_all_yearly.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels yearly\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\")\n",
    "all_channels_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_analysis: ChannelAnalysis = ChannelAnalysis(message_df=main_channel_analysis.messages_df)\n",
    "channel_analysis.restrict_to_channels(lore_channels)\n",
    "\n",
    "logging.getLogger().info(f\"Plotting message count by day\")\n",
    "df: pd.DataFrame = channel_analysis.day_number_of_messages().copy()\n",
    "creation_date_series_lore_yearly = df[\"created_at\"].value_counts()\n",
    "creation_date_series_lore_yearly = creation_date_series_lore_yearly.sort_index()\n",
    "\n",
    "creation_date_series_lore_yearly.index = pd.to_datetime(creation_date_series_lore_yearly.index).year\n",
    "\n",
    "all_channels_fig = px.histogram(creation_date_series_lore_yearly, \n",
    "                    x = creation_date_series_lore_yearly.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels yearly\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    color_discrete_sequence=['red'],\n",
    "                    barmode=\"group\")\n",
    "all_channels_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both figure\n",
    "# Combine the histograms\n",
    "fig = go.Figure()\n",
    "\n",
    "creation_date_series_all_normalized = creation_date_series_all_yearly.copy()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_yearly.copy()\n",
    "creation_date_series_all_normalized  = creation_date_series_all_normalized / creation_date_series_all_normalized.max()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_normalized / creation_date_series_lore_normalized.max()\n",
    "\n",
    "all_channels_fig_probability = px.bar(creation_date_series_all_normalized, \n",
    "                    x = creation_date_series_all_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "lore_channels_fig_probability = px.bar(creation_date_series_lore_normalized, \n",
    "                    x = creation_date_series_lore_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "# Add traces from both histograms\n",
    "for trace in all_channels_fig_probability.data:\n",
    "    trace.opacity = 1\n",
    "    fig.add_trace(trace)\n",
    "for trace in lore_channels_fig_probability.data:\n",
    "    trace.opacity = 0.5\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_traces(marker_line_width=0)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Lore channels on top of all channels yearly\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Messages to max ratio\",\n",
    "    barmode='overlay',\n",
    "    template=\"plotly\",\n",
    "    bargap=0,\n",
    "    bargroupgap=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('file:///home/stefan/Downloads/features(61).geojson') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "region_occurence_offtop_analysis = ChannelAnalysis.from_channel_analysis(main_channel_analysis)\n",
    "region_occurence_offtop_analysis.remove_channels_from_current(lore_channels)\n",
    "region_occurence_messages = region_occurence_offtop_analysis.copy_messages_df_current_channels()\n",
    "region_occurence_messages = region_occurence_messages[~region_occurence_messages[\"author_id\"].isin(bot_users)]\n",
    "\n",
    "region_occurence_count: dict[str, list[str]] = {}\n",
    "for region_id, region_values in regions.items():\n",
    "  region_occurence_count[region_id] = 0\n",
    "  for message_content in region_occurence_messages[\"content\"]:\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            region_occurence_count[region_id] += message_content.count(region_value)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "region_occurence_count = pd.DataFrame.from_dict(region_occurence_count, orient='index', columns=[\"occurence\"])\n",
    "fig = px.choropleth(region_occurence_count, geojson=counties, locations=region_occurence_count.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"Wystąpienia kraju (Kanały Lorowe)\"\n",
    "                          )\n",
    "fig.update_geos(visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":100,\"l\":0,\"b\":0})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_occurence_lore_analysis = ChannelAnalysis.from_channel_analysis(main_channel_analysis)\n",
    "region_occurence_lore_analysis.restrict_to_channels(lore_channels)\n",
    "region_occurence_messages = region_occurence_lore_analysis.copy_messages_df_current_channels()\n",
    "region_occurence_messages = region_occurence_messages[~region_occurence_messages[\"author_id\"].isin(bot_users)]\n",
    "\n",
    "region_occurence_count: dict[str, list[str]] = {}\n",
    "for region_id, region_values in regions.items():\n",
    "  region_occurence_count[region_id] = 0\n",
    "  for message_content in region_occurence_messages[\"content\"]:\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            region_occurence_count[region_id] += message_content.count(region_value)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "region_occurence_count = pd.DataFrame.from_dict(region_occurence_count, orient='index', columns=[\"occurence\"])\n",
    "fig = px.choropleth(region_occurence_count, geojson=counties, locations=region_occurence_count.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"Wystąpienia kraju (Pozostałe kanały)\"\n",
    "                          )\n",
    "fig.update_geos(visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":150,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_occurence_count_down = region_occurence_count[region_occurence_count[\"occurence\"] < region_occurence_count[\"occurence\"].quantile(0.70)]\n",
    "fig = px.choropleth(region_occurence_count_down, geojson=counties, locations=region_occurence_count_down.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\"\n",
    "                          )\n",
    "fig.update_geos(visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_occurence_count_non_human = region_occurence_count[~region_occurence_count.index.isin(human_countries)]\n",
    "fig = px.choropleth(region_occurence_count_non_human, geojson=counties, locations=region_occurence_count_non_human.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"Wystąpienia krajów NPC\"\n",
    "                          )\n",
    "fig.update_geos(visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":150,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel words to lore phrases\n",
    "import datetime\n",
    "\n",
    "\n",
    "words_to_lore_phrases = main_channel_analysis.messages_df.copy()\n",
    "#words_to_lore_phrases = words_to_lore_phrases.set_index(\"id\")\n",
    "words_to_lore_phrases = words_to_lore_phrases[~words_to_lore_phrases[\"author_id\"].isin(bot_users)]\n",
    "\n",
    "words_to_lore_phrases[\"created_at\"] = pd.to_datetime(words_to_lore_phrases[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S.%f%z\", errors='coerce').fillna(\n",
    "    pd.to_datetime(words_to_lore_phrases[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S%z\", errors='coerce')\n",
    ")\n",
    "\n",
    "def replace_emojis(message_content: str):\n",
    "    import re\n",
    "    emoji_char = \"�\"\n",
    "    result = re.sub(\"<.+:.+>\", emoji_char, message_content)\n",
    "    for emoji in emojis:\n",
    "        result = result.replace(emoji, emoji_char)\n",
    "    return result\n",
    "\n",
    "words_to_lore_phrases[\"content\"] = words_to_lore_phrases[\"content\"].apply(lambda x: replace_emojis(x))\n",
    "\n",
    "words_to_lore_phrases = words_to_lore_phrases[(words_to_lore_phrases[\"content\"].str.len() > 2) | (words_to_lore_phrases[\"attachments\"].str.len() > 0)]\n",
    "\n",
    "words_to_lore_phrases[\"words\"] = words_to_lore_phrases[\"content\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "def lore_occurences_in_message(message_content: str) -> int:\n",
    "    result = 0\n",
    "    for region_id, region_values in regions.items():\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            result += message_content.count(region_value)\n",
    "    for lore_word in other_lore_words:\n",
    "        result += message_content.count(lore_word)\n",
    "    return result\n",
    "words_to_lore_phrases[\"lore_phrases\"] = words_to_lore_phrases[\"content\"].apply(lambda x: lore_occurences_in_message(x))\n",
    "\n",
    "def special_characters_number(message_content: str) -> int:\n",
    "    result = 0\n",
    "    for character in special_characters:\n",
    "        found = message_content.find(character)\n",
    "        if(found > 0):\n",
    "            result += found\n",
    "    return result\n",
    "words_to_lore_phrases[\"special_characters\"] = words_to_lore_phrases[\"content\"].apply(lambda x: special_characters_number(x))\n",
    "\n",
    "def number_of_attachments(x: list | None):\n",
    "    if(x is None):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x)\n",
    "words_to_lore_phrases[\"attachments_count\"] = words_to_lore_phrases[\"attachments\"].apply(lambda x: number_of_attachments(x))\n",
    "words_to_lore_phrases[\"message_length\"] = words_to_lore_phrases[\"content\"].apply(lambda x: len(x))\n",
    "def test(x):\n",
    "    window_length = \"3h\"\n",
    "    result = x.rolling(window_length, center=True, on=\"created_at\")[\"created_at\"].count()\n",
    "    lore_roll = x.rolling(window_length, center=True, on=\"created_at\")[\"lore_phrases\"].sum()\n",
    "    special_characters_roll = x.rolling(window_length, center=True, on=\"created_at\")[\"special_characters\"].sum()\n",
    "    result = result.to_frame()\n",
    "    result[\"lore_phrases\"] = lore_roll\n",
    "    result[\"special_characters\"] = special_characters_roll\n",
    "    return result\n",
    "b = words_to_lore_phrases.groupby('channel_id').apply(lambda group: test(group))\n",
    "b = b.reset_index(level=0)\n",
    "words_to_lore_phrases[\"followup_messages\"] = b[\"created_at\"]\n",
    "words_to_lore_phrases[\"followup_messages_lore\"] = b[\"lore_phrases\"]\n",
    "words_to_lore_phrases[\"followup_messages_special_characters\"] = b[\"special_characters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_lore_phrases_channels = words_to_lore_phrases.groupby(\"channel_id\").agg(\n",
    "    total_words=(\"words\", 'sum'),\n",
    "    total_lore_phrases=(\"lore_phrases\", 'sum'),\n",
    "    total_attachments=(\"attachments_count\", \"sum\"),\n",
    "    avg_message_length=(\"message_length\", \"median\"),\n",
    "    avg_followup_messages=(\"followup_messages\", \"mean\")\n",
    ")\n",
    "words_to_lore_phrases_channels = words_to_lore_phrases_channels[words_to_lore_phrases_channels[\"total_words\"] >= 200]\n",
    "words_to_lore_phrases_channels[\"channel_name\"] = words_to_lore_phrases_channels.index.map(get_channel_name)\n",
    "words_to_lore_phrases_channels[\"lore_to_words_ratio\"] = words_to_lore_phrases_channels[\"total_lore_phrases\"]/words_to_lore_phrases_channels[\"total_words\"]\n",
    "words_to_lore_phrases_channels[\"attachments_lore_to_words_ratio\"] = words_to_lore_phrases_channels[\"lore_to_words_ratio\"]*words_to_lore_phrases_channels[\"total_attachments\"]\n",
    "words_to_lore_phrases_channels[\"word_length_altw\"] = words_to_lore_phrases_channels[\"attachments_lore_to_words_ratio\"]*words_to_lore_phrases_channels[\"avg_message_length\"]\n",
    "words_to_lore_phrases_channels[\"all_variables\"] = words_to_lore_phrases_channels[\"word_length_altw\"]*words_to_lore_phrases_channels[\"avg_followup_messages\"]\n",
    "words_to_lore_phrases_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def is_lore_message(channel_id):\n",
    "    if(channel_id in lore_channels):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(ml_channels)]\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = words_to_lore_phrases_ml[\"channel_id\"].apply(lambda x: is_lore_message(x))\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"attachments\",\n",
    "    \"reactions\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"edited_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\",\n",
    "    \"referenced_message\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "\n",
    "X = words_to_lore_phrases_ml.drop(\"lore_message\", axis=1)\n",
    "y = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "for i in range(2): #red is 0, blue is 1\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)\n",
    "\n",
    "#comp = pd.DataFrame()\n",
    "#comp[\"pred\"] = list(y_pred)\n",
    "#words_to_lore_phrases[\"predicted\"] = comp[\"pred\"]\n",
    "#words_to_lore_phrases[\"real\"] = words_to_lore_phrases[\"channel_id\"].apply(lambda x: is_lore_message(x))\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "feature_names = [\"words\", \"lore_phrases\", \"special_characters\", \"attachments_count\", \"message_length\", \"followup_messages\", \"followup_messages_lore\", \"followup_messages_special_characters\"]\n",
    "import pandas as pd\n",
    "pd.Series(tree.feature_importances_, index=feature_names).plot.bar()\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#param_dist = {'n_estimators': randint(50,500),\n",
    "#              'max_depth': randint(1,20)}\n",
    "#\n",
    "## Create a random forest classifier\n",
    "#rf = RandomForestClassifier()\n",
    "#\n",
    "## Use random search to find the best hyperparameters\n",
    "#rand_search = RandomizedSearchCV(rf, \n",
    "#                                 param_distributions = param_dist, \n",
    "#                                 n_iter=5, \n",
    "#                                 cv=5)\n",
    "#\n",
    "## Fit the random search object to the data\n",
    "#rand_search.fit(X_train, y_train)\n",
    "#\n",
    "## Create a variable for the best model\n",
    "#best_rf = rand_search.best_estimator_\n",
    "#\n",
    "## Print the best hyperparameters\n",
    "#print('Best hyperparameters:',  rand_search.best_params_)\n",
    "#\n",
    "## Generate predictions with the best model\n",
    "#y_pred = best_rf.predict(X_test)\n",
    "#\n",
    "## Create the confusion matrix\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "#\n",
    "#ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "#\n",
    "#y_pred = best_rf.predict(X_test)\n",
    "#\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#precision = precision_score(y_test, y_pred)\n",
    "#recall = recall_score(y_test, y_pred)\n",
    "#\n",
    "#print(\"Accuracy:\", accuracy)\n",
    "#print(\"Precision:\", precision)\n",
    "#print(\"Recall:\", recall)\n",
    "#\n",
    "## Create a series containing feature importances from the model and feature names from the training data\n",
    "#feature_importances = pd.Series(best_rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "#\n",
    "## Plot a simple bar chart\n",
    "#feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def is_lore_message(channel_id):\n",
    "    if(channel_id in lore_channels):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(ml_channels)]\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = words_to_lore_phrases_ml[\"channel_id\"].apply(lambda x: is_lore_message(x))\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"attachments\",\n",
    "    \"reactions\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"edited_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\",\n",
    "    \"referenced_message\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "\n",
    "X = words_to_lore_phrases_ml.drop(\"lore_message\", axis=1)\n",
    "y = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "from xgboost import plot_importance\n",
    "xgb_model.get_booster().feature_names = [\"words\", \"lore_phrases\", \"special_characters\", \"attachments_count\", \"message_length\", \"followup_messages\", \"followup_messages_lore\", \"followup_messages_special_characters\"]\n",
    "plot_importance(xgb_model, importance_type='weight')\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scroll through mixed channel and see the results\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(dig_channels)]\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"attachments\",\n",
    "    \"reactions\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"edited_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\",\n",
    "    \"referenced_message\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = rf.predict(words_to_lore_phrases_ml)\n",
    "words_to_lore_phrases_pred = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_pred = words_to_lore_phrases_pred[words_to_lore_phrases_pred[\"channel_id\"].isin(dig_channels)]\n",
    "words_to_lore_phrases_pred[\"lore_message\"] = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "h = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
