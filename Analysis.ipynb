{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Handle imports in src\n",
    "main_folder = os.getcwd()\n",
    "src_path = os.path.join(main_folder, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "import logging\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from VariableTypeEnum import VariableTypeEnum\n",
    "from VarsManager import VarsManager\n",
    "from src.ChannelAnalysis import ChannelAnalysis\n",
    "from LoreInfo import regions, bot_users, lore_channels, human_countries, ml_channels, dig_channels, other_lore_words, special_characters, emojis, log_channels, offtop_ml_channels\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "vars_manager = VarsManager()\n",
    "channel_names = vars_manager.vars[VariableTypeEnum.CHANNEL_NAMES]\n",
    "user_names = vars_manager.vars[VariableTypeEnum.USER_NICKNAMES]\n",
    "def get_channel_name(id):\n",
    "    id = str(id)\n",
    "    if(id in channel_names):\n",
    "        return channel_names[id]\n",
    "    else:\n",
    "        return None\n",
    "def get_user_name(id):\n",
    "    id = str(id)\n",
    "    id = hash(id)\n",
    "    if(id in user_names):\n",
    "        return user_names[id]\n",
    "    else:\n",
    "        return str(id)\n",
    "    \n",
    "main_channel_analysis: ChannelAnalysis\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Preparing data\")\n",
    "    main_channel_analysis = ChannelAnalysis(content_matters=True)\n",
    "    logging.info(\"Starting the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data and create numerical values for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = main_channel_analysis.messages_df.copy()\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "df = df[~df[\"channel_id\"].isin(log_channels)]\n",
    "df = df[(df[\"content\"].str.len() > 2) | (df[\"attachments\"].str.len() > 0)]\n",
    "df = df[~df[\"author_id\"].isin(bot_users)]\n",
    "\n",
    "\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S.%f%z\", errors='coerce').fillna(\n",
    "    pd.to_datetime(df[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S%z\", errors='coerce')\n",
    ")\n",
    "\n",
    "df[\"words\"] = df[\"content\"].apply(lambda x: len(x.split()))\n",
    "df[\"message_length\"] = df[\"content\"].apply(lambda x: len(x))\n",
    "def number_of_attachments(x: list | None):\n",
    "    if(x is None):\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x)\n",
    "df[\"attachments_count\"] = df[\"attachments\"].apply(lambda x: number_of_attachments(x))\n",
    "def special_characters_number(message_content: str) -> int:\n",
    "    result = 0\n",
    "    for character in special_characters:\n",
    "        found = message_content.find(character)\n",
    "        if(found > 0):\n",
    "            result += found\n",
    "    return result\n",
    "df[\"special_characters\"] = df[\"content\"].apply(lambda x: special_characters_number(x))\n",
    "def lore_occurences_in_message(message_content: str) -> int:\n",
    "    result = 0\n",
    "    for region_id, region_values in regions.items():\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            result += message_content.count(region_value)\n",
    "    for lore_word in other_lore_words:\n",
    "        result += message_content.count(lore_word)\n",
    "    return result\n",
    "df[\"lore_phrases\"] = df[\"content\"].apply(lambda x: lore_occurences_in_message(x))\n",
    "df = df.drop(columns=[\"attachments\", \"reactions\", \"edited_at\", \"referenced_message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows = 7, cols = 2)\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "row_num, col_num = 1, 1\n",
    "for col in num_cols:\n",
    "  fig.add_trace(go.Box(y=df[col], name=col), row=row_num, col=col_num)\n",
    "  if col_num == 2:\n",
    "    col_num = 1\n",
    "    row_num += 1\n",
    "  else:\n",
    "    col_num += 1\n",
    "    print(row_num)\n",
    "fig.update_layout(height=1300, width=600, title_text=\"Side By Side Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data is quite dirty even after filtering log channels and bot messages, but at the same time the data is quite interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot server messages\n",
    "We can clearly see several boom periods. What's interesting is that messages on non-lore channels grew with messages on lore channels, pointing to a correlation between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_date_series = df.copy()\n",
    "creation_date_series[\"created_at\"] = creation_date_series[\"created_at\"].dt.date\n",
    "creation_date_series = creation_date_series[\"created_at\"].value_counts()\n",
    "creation_date_series = creation_date_series.sort_index()\n",
    "\n",
    "all_channels_fig = px.bar(creation_date_series, \n",
    "                    x = creation_date_series.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on the server\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['purple'],\n",
    ")\n",
    "\n",
    "for trace in all_channels_fig.data:\n",
    "    trace.opacity = 1\n",
    "    all_channels_fig.add_trace(trace)\n",
    "all_channels_fig.update_traces(marker_line_width=0)\n",
    "all_channels_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_date_series_lore: pd.DataFrame = df[df[\"channel_id\"].isin(lore_channels)].copy()\n",
    "creation_date_series_lore[\"created_at\"] = creation_date_series_lore[\"created_at\"].dt.date\n",
    "creation_date_series_lore = creation_date_series_lore[\"created_at\"].value_counts()\n",
    "creation_date_series_lore = creation_date_series_lore.sort_index()\n",
    "\n",
    "lore_channels_fig = px.bar(creation_date_series_lore, \n",
    "                    x = creation_date_series_lore.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red'],\n",
    ")\n",
    "\n",
    "for trace in lore_channels_fig.data:\n",
    "    trace.opacity = 1\n",
    "    lore_channels_fig.add_trace(trace)\n",
    "lore_channels_fig.update_traces(marker_line_width=0)\n",
    "lore_channels_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_date_series_offtop: pd.DataFrame = df[~df[\"channel_id\"].isin(lore_channels)].copy()\n",
    "creation_date_series_offtop[\"created_at\"] = creation_date_series_offtop[\"created_at\"].dt.date\n",
    "creation_date_series_offtop = creation_date_series_offtop[\"created_at\"].value_counts()\n",
    "creation_date_series_offtop = creation_date_series_offtop.sort_index()\n",
    "\n",
    "offtop_channels_fig = px.bar(creation_date_series_offtop, \n",
    "                    x = creation_date_series_offtop.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on offtop channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "for trace in offtop_channels_fig.data:\n",
    "    trace.opacity = 1\n",
    "    offtop_channels_fig.add_trace(trace)\n",
    "offtop_channels_fig.update_traces(marker_line_width=0)\n",
    "offtop_channels_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "creation_date_series_offtop_normalized = creation_date_series_offtop.copy()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore.copy()\n",
    "\n",
    "all_channels_fig_probability = px.bar(creation_date_series_offtop_normalized, \n",
    "                    x = creation_date_series_offtop_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "lore_channels_fig_probability = px.bar(creation_date_series_lore_normalized, \n",
    "                    x = creation_date_series_lore_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "for trace in all_channels_fig_probability.data:\n",
    "    trace.opacity = 1\n",
    "    fig.add_trace(trace)\n",
    "for trace in lore_channels_fig_probability.data:\n",
    "    trace.opacity = 0.5\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_traces(marker_line_width=0)\n",
    "fig.update_layout(\n",
    "    title=\"Lore channels and offtop channels\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Messages to max ratio\",\n",
    "    barmode='overlay',\n",
    "    template=\"plotly\",\n",
    "    bargap=0,\n",
    "    bargroupgap=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "creation_date_series_offtop_normalized = creation_date_series_offtop.copy()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore.copy()\n",
    "creation_date_series_offtop_normalized  = creation_date_series_offtop_normalized / creation_date_series_offtop_normalized.max()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_normalized / creation_date_series_lore_normalized.max()\n",
    "\n",
    "all_channels_fig_probability = px.bar(creation_date_series_offtop_normalized, \n",
    "                    x = creation_date_series_offtop_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "lore_channels_fig_probability = px.bar(creation_date_series_lore_normalized, \n",
    "                    x = creation_date_series_lore_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "for trace in all_channels_fig_probability.data:\n",
    "    trace.opacity = 1\n",
    "    fig.add_trace(trace)\n",
    "for trace in lore_channels_fig_probability.data:\n",
    "    trace.opacity = 0.5\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_traces(marker_line_width=0)\n",
    "fig.update_layout(\n",
    "    title=\"Lore channels and offtop channels\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Messages to max ratio\",\n",
    "    barmode='overlay',\n",
    "    template=\"plotly\",\n",
    "    bargap=0,\n",
    "    bargroupgap=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_date_series_all_yearly: pd.DataFrame = df[~df[\"channel_id\"].isin(lore_channels)].copy()\n",
    "creation_date_series_all_yearly[\"created_at\"] = creation_date_series_all_yearly[\"created_at\"].dt.date\n",
    "creation_date_series_all_yearly = creation_date_series_all_yearly[\"created_at\"].value_counts()\n",
    "creation_date_series_all_yearly = creation_date_series_all_yearly.sort_index()\n",
    "\n",
    "creation_date_series_all_yearly.index = pd.to_datetime(creation_date_series_all_yearly.index).year\n",
    "\n",
    "offtop_channels_fig = px.histogram(creation_date_series_all_yearly, \n",
    "                    x = creation_date_series_all_yearly.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on offtop channels yearly\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\")\n",
    "offtop_channels_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_date_series_lore_yearly: pd.DataFrame = df[df[\"channel_id\"].isin(lore_channels)].copy()\n",
    "creation_date_series_lore_yearly[\"created_at\"] = creation_date_series_lore_yearly[\"created_at\"].dt.date\n",
    "creation_date_series_lore_yearly = creation_date_series_lore_yearly[\"created_at\"].value_counts()\n",
    "creation_date_series_lore_yearly = creation_date_series_lore_yearly.sort_index()\n",
    "\n",
    "creation_date_series_lore_yearly.index = pd.to_datetime(creation_date_series_lore_yearly.index).year\n",
    "\n",
    "offtop_channels_fig = px.histogram(creation_date_series_lore_yearly, \n",
    "                    x = creation_date_series_lore_yearly.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels yearly\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    color_discrete_sequence=['red'],\n",
    "                    barmode=\"group\")\n",
    "offtop_channels_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "creation_date_series_offtop_normalized = creation_date_series_all_yearly.copy()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_yearly.copy()\n",
    "\n",
    "creation_date_series_offtop_normalized = creation_date_series_offtop_normalized.groupby(level=0).sum()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_normalized.groupby(level=0).sum()\n",
    "\n",
    "creation_date_series_offtop_normalized  = creation_date_series_offtop_normalized / creation_date_series_offtop_normalized.max()\n",
    "creation_date_series_lore_normalized = creation_date_series_lore_normalized / creation_date_series_lore_normalized.max()\n",
    "\n",
    "all_channels_fig_probability = px.bar(creation_date_series_offtop_normalized, \n",
    "                    x = creation_date_series_offtop_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on all channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['blue'],\n",
    ")\n",
    "\n",
    "lore_channels_fig_probability = px.bar(creation_date_series_lore_normalized, \n",
    "                    x = creation_date_series_lore_normalized.index, \n",
    "                    y = \"count\",\n",
    "                    title=\"Messages on lore channels\",\n",
    "                    labels={\n",
    "                        \"count\": \"Count\",\n",
    "                        \"created_at\": \"Date\"\n",
    "                    },\n",
    "                    barmode=\"group\",\n",
    "                    color_discrete_sequence=['red']\n",
    ")\n",
    "\n",
    "for trace in all_channels_fig_probability.data:\n",
    "    trace.opacity = 1\n",
    "    fig.add_trace(trace)\n",
    "for trace in lore_channels_fig_probability.data:\n",
    "    trace.opacity = 0.5\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "fig.update_traces(marker_line_width=0)\n",
    "fig.update_layout(\n",
    "    title=\"Lore channels on top of offtop channels yearly\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Messages to max ratio\",\n",
    "    barmode='overlay',\n",
    "    template=\"plotly\",\n",
    "    bargap=0,\n",
    "    bargroupgap=0\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that pandemic time of 2020 was the maximum point both for lore and non-lore participation. A trendline can also be seen (ignoring years of 2017-2018 when a lot of lore was being written on the offtop channels), pointing to a shift of the server's profile from RP-based to more community based server where lore is a secondary endeavour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server messages by weekday\n",
    "What's interesting is that while channels that are related to real-life show decrease on weekends, the lore channels experience a decrease on thursdays, but on a smaller scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_graph(weekday_df: pd.DataFrame, label: str):\n",
    "    weekday_df[\"created_at\"] = pd.to_datetime(weekday_df[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S.%f%z\", errors='coerce').fillna(\n",
    "            pd.to_datetime(weekday_df[\"created_at\"], utc=True, format=\"%Y-%m-%d %H:%M:%S%z\", errors='coerce')\n",
    "        )\n",
    "    weekday_df[\"weekday\"] = weekday_df['created_at'].dt.weekday\n",
    "    weekday_df = weekday_df.groupby(\"weekday\").count()\n",
    "    all_messages_count = weekday_df[\"created_at\"].sum()\n",
    "    if(all_messages_count == 0):\n",
    "        all_messages_count = 1\n",
    "    weekday_df[\"created_at\"] = weekday_df['created_at']/all_messages_count\n",
    "\n",
    "    day_dict = {\n",
    "        0: 'Monday',\n",
    "        1: 'Tuesday',\n",
    "        2: 'Wednesday',\n",
    "        3: 'Thursday',\n",
    "        4: 'Friday',\n",
    "        5: 'Saturday',\n",
    "        6: 'Sunday'\n",
    "    }\n",
    "\n",
    "    ax = None\n",
    "    weekday_df[\"weekday_name\"] = weekday_df.index.to_series().replace(day_dict)\n",
    "    ax = weekday_df.plot(ax=ax,x=\"weekday_name\", xlabel=\"Weekday\", y=\"created_at\", ylabel=\"Messages\", title=label, ylim=0, legend=False)\n",
    "    plt.show(ax)\n",
    "\n",
    "plot_graph(df.copy(), \"All channels\")\n",
    "plot_graph(df[df[\"channel_id\"].isin(lore_channels)].copy(), \"Lore channels\")\n",
    "plot_graph(df[~df[\"channel_id\"].isin(lore_channels)].copy(), \"Offtop channels\")\n",
    "plot_graph(df[df[\"channel_id\"].isin([576027933634854912])].copy(), \"Real-life related channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participation by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One user with a lot of activity (me) who is a server owner can be seen. Others are pretty equally active, but some have more lore participation than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_participation_df = df[~df[\"channel_id\"].isin(lore_channels)]\n",
    "user_participation_df = user_participation_df.groupby(\"author_id\").count()\n",
    "user_participation_df[\"name\"] = user_participation_df.index.map(get_user_name)\n",
    "fig = px.pie(user_participation_df, values='id', names='name', title='Offtop user participation on the server')\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_participation_lore_df = df[df[\"channel_id\"].isin(lore_channels)]\n",
    "user_participation_lore_df = user_participation_lore_df.groupby(\"author_id\").count()\n",
    "user_participation_lore_df[\"name\"] = user_participation_lore_df.index.map(get_user_name)\n",
    "fig = px.pie(user_participation_lore_df, values='id', names='name', title='Lore user participation on the server')\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps\n",
    "Maps were the most interesting part for me personally, but analitically only 2 things stand out - active human-led countries have much higher mention ratio and NPC countries that have historically been important or funny have a higher ratio as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('file:///home/stefan/Downloads/features(61).geojson') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "region_occurence_all_analysis: pd.DataFrame = df.copy()\n",
    "\n",
    "region_occurence_count: dict[str, list[str]] = {}\n",
    "for region_id, region_values in regions.items():\n",
    "  region_occurence_count[region_id] = 0\n",
    "  for message_content in region_occurence_all_analysis[\"content\"]:\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            region_occurence_count[region_id] += message_content.count(region_value)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "region_occurence_count = pd.DataFrame.from_dict(region_occurence_count, orient='index', columns=[\"occurence\"])\n",
    "fig = px.choropleth(region_occurence_count, geojson=counties, locations=region_occurence_count.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"Country mentions\"\n",
    "                          )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":100,\"l\":0,\"b\":0})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_occurence_all_analysis: pd.DataFrame = df.copy()\n",
    "\n",
    "region_occurence_count: dict[str, list[str]] = {}\n",
    "for region_id, region_values in regions.items():\n",
    "  region_occurence_count[region_id] = 0\n",
    "  for message_content in region_occurence_all_analysis[\"content\"]:\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            region_occurence_count[region_id] += message_content.count(region_value)\n",
    "\n",
    "region_occurence_count = pd.DataFrame.from_dict(region_occurence_count, orient='index', columns=[\"occurence\"])\n",
    "region_occurence_count_down = region_occurence_count[region_occurence_count[\"occurence\"] < region_occurence_count[\"occurence\"].quantile(0.70)]\n",
    "fig = px.choropleth(region_occurence_count_down, geojson=counties, locations=region_occurence_count_down.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"Country mentions with top countries removed\"\n",
    "                          )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":150,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_occurence_all_analysis: pd.DataFrame = df.copy()\n",
    "\n",
    "region_occurence_count: dict[str, list[str]] = {}\n",
    "for region_id, region_values in regions.items():\n",
    "  region_occurence_count[region_id] = 0\n",
    "  for message_content in region_occurence_all_analysis[\"content\"]:\n",
    "        message_content = message_content.lower()\n",
    "        for region_value in region_values:\n",
    "            region_occurence_count[region_id] += message_content.count(region_value)\n",
    "\n",
    "region_occurence_count = pd.DataFrame.from_dict(region_occurence_count, orient='index', columns=[\"occurence\"])\n",
    "region_occurence_count_non_human = region_occurence_count[~region_occurence_count.index.isin(human_countries)]\n",
    "fig = px.choropleth(region_occurence_count_non_human, geojson=counties, locations=region_occurence_count_non_human.index, color=\"occurence\",\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           labels={'unemp':'unemployment rate'},\n",
    "                            featureidkey=\"properties.id\",\n",
    "                            title=\"NPC-countries mentions\"\n",
    "                          )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":150,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "I decided that i need a machine learning model that will classify messages as \"being lore or a lore related discussion\" to search through a big, old and mixed channel that has some old lore messages buried by the offtopic spam beneath.\n",
    "\n",
    "After analysing numerous messages' contents i realized that lore messages usually differ in: lore phrases mentions (obviously), special characters use (when people get serious they care more about punctuation) and activity around the message (random memes about lore contain lore phrases but rarely any activity beyond a simple \"XD\").\n",
    "\n",
    "I have tried randomforest and xgboost models. Xgboost achieved better accuracy and precision, but it's lower recall for lore messages made it slightly worse when tested on channels outside the dataset. Is is also interesting that Xgboost decided that special characters are more important than lore phrases in followup messages, which may explain differences in accuracy and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_lore_phrases = df.copy()\n",
    "\n",
    "def replace_emojis(message_content: str):\n",
    "    import re\n",
    "    emoji_char = \"�\"\n",
    "    result = re.sub(\"<.+:.+>\", emoji_char, message_content)\n",
    "    for emoji in emojis:\n",
    "        result = result.replace(emoji, emoji_char)\n",
    "    return result\n",
    "words_to_lore_phrases[\"content\"] = words_to_lore_phrases[\"content\"].apply(lambda x: replace_emojis(x))\n",
    "\n",
    "def test(x):\n",
    "    window_length = \"3h\"\n",
    "    result = x.rolling(window_length, center=True, on=\"created_at\")[\"created_at\"].count()\n",
    "    lore_roll = x.rolling(window_length, center=True, on=\"created_at\")[\"lore_phrases\"].sum()\n",
    "    special_characters_roll = x.rolling(window_length, center=True, on=\"created_at\")[\"special_characters\"].sum()\n",
    "    result = result.to_frame()\n",
    "    result[\"lore_phrases\"] = lore_roll\n",
    "    result[\"special_characters\"] = special_characters_roll\n",
    "    return result\n",
    "b = words_to_lore_phrases.groupby('channel_id').apply(lambda group: test(group))\n",
    "b = b.reset_index(level=0)\n",
    "words_to_lore_phrases[\"followup_messages\"] = b[\"created_at\"]\n",
    "words_to_lore_phrases[\"followup_messages_lore\"] = b[\"lore_phrases\"]\n",
    "words_to_lore_phrases[\"followup_messages_special_characters\"] = b[\"special_characters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_lore_phrases_channels = words_to_lore_phrases.groupby(\"channel_id\").agg(\n",
    "    total_words=(\"words\", 'sum'),\n",
    "    total_lore_phrases=(\"lore_phrases\", 'sum'),\n",
    "    total_attachments=(\"attachments_count\", \"sum\"),\n",
    "    avg_message_length=(\"message_length\", \"median\"),\n",
    "    avg_followup_messages=(\"followup_messages\", \"mean\")\n",
    ")\n",
    "words_to_lore_phrases_channels = words_to_lore_phrases_channels[words_to_lore_phrases_channels[\"total_words\"] >= 200]\n",
    "words_to_lore_phrases_channels[\"channel_name\"] = words_to_lore_phrases_channels.index.map(get_channel_name)\n",
    "words_to_lore_phrases_channels[\"lore_to_words_ratio\"] = words_to_lore_phrases_channels[\"total_lore_phrases\"]/words_to_lore_phrases_channels[\"total_words\"]\n",
    "words_to_lore_phrases_channels[\"attachments_lore_to_words_ratio\"] = words_to_lore_phrases_channels[\"lore_to_words_ratio\"]*words_to_lore_phrases_channels[\"total_attachments\"]\n",
    "words_to_lore_phrases_channels[\"word_length_altw\"] = words_to_lore_phrases_channels[\"attachments_lore_to_words_ratio\"]*words_to_lore_phrases_channels[\"avg_message_length\"]\n",
    "words_to_lore_phrases_channels[\"all_variables\"] = words_to_lore_phrases_channels[\"word_length_altw\"]*words_to_lore_phrases_channels[\"avg_followup_messages\"]\n",
    "words_to_lore_phrases_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from xgboost import plot_importance\n",
    "\n",
    "def is_lore_message(channel_id):\n",
    "    if(channel_id in lore_channels):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(ml_channels)]\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = words_to_lore_phrases_ml[\"channel_id\"].apply(lambda x: is_lore_message(x))\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "\n",
    "X = words_to_lore_phrases_ml.drop(\"lore_message\", axis=1)\n",
    "y = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "for i in range(2): #red is 0, blue is 1\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)\n",
    "\n",
    "feature_names = ['Words', 'Message length', 'Attachments count', 'Special characters', 'Lore phrases', 'Followup messages', 'Followup messagers lore phrases', 'Followup messages special characters']\n",
    "import pandas as pd\n",
    "pd.Series(tree.feature_importances_, index=feature_names).plot.bar()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def is_lore_message(channel_id):\n",
    "    if(channel_id in lore_channels):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(ml_channels)]\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = words_to_lore_phrases_ml[\"channel_id\"].apply(lambda x: is_lore_message(x))\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "\n",
    "X = words_to_lore_phrases_ml.drop(\"lore_message\", axis=1)\n",
    "y = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "from xgboost import plot_importance\n",
    "feature_names = ['Words', 'Message length', 'Attachments count', 'Special characters', 'Lore phrases', 'Followup messages', 'Followup messagers lore phrases', 'Followup messages special characters']\n",
    "xgb_model.get_booster().feature_names = feature_names\n",
    "plot_importance(xgb_model, importance_type='weight')\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model on new channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scroll through mixed channel and see the results\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml[words_to_lore_phrases_ml[\"channel_id\"].isin(dig_channels)]\n",
    "\n",
    "fields = [\n",
    "    \"id\",\n",
    "    \"content\",\n",
    "    \"author_id\",\n",
    "    \"thread_messages\",\n",
    "    \"created_at\",\n",
    "    \"pinned\",\n",
    "    \"channel_id\"\n",
    "]\n",
    "words_to_lore_phrases_ml = words_to_lore_phrases_ml.drop(fields, axis=1)\n",
    "\n",
    "words_to_lore_phrases_ml.rename(columns={\n",
    "    'words': 'Words', \n",
    "    'lore_phrases': 'Lore phrases', \n",
    "    'special_characters': 'Special characters', \n",
    "    'attachments_count': 'Attachments count', \n",
    "    'message_length': 'Message length', \n",
    "    'followup_messages': 'Followup messages', \n",
    "    'followup_messages_lore': 'Followup messagers lore phrases', \n",
    "    'followup_messages_special_characters': 'Followup messages special characters'\n",
    "}, inplace=True)\n",
    "\n",
    "words_to_lore_phrases_ml[\"lore_message\"] = xgb_model.predict(words_to_lore_phrases_ml)\n",
    "words_to_lore_phrases_pred = words_to_lore_phrases.copy()\n",
    "words_to_lore_phrases_pred = words_to_lore_phrases_pred[words_to_lore_phrases_pred[\"channel_id\"].isin(dig_channels)]\n",
    "words_to_lore_phrases_pred[\"lore_message\"] = words_to_lore_phrases_ml[\"lore_message\"]\n",
    "words_to_lore_phrases_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
